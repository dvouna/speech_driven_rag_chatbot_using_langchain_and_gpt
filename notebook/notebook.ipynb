{"cells":[{"source":"# RAG Chatbot With Audio\n\n","metadata":{},"cell_type":"markdown","id":"bbe141fc-b34e-44c5-8c7f-e5e846bd35a0"},{"source":"# Import the required packages \nimport os\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\nfrom langchain_community.document_loaders import UnstructuredHTMLLoader \nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nimport openai\nfrom langchain_community.document_loaders import PyPDFLoader\nimport pathlib\nfrom langchain.vectorstores import Chroma","metadata":{"executionCancelledAt":null,"executionTime":2799,"lastExecutedAt":1750442143327,"lastExecutedByKernel":"3ba2e33b-5d82-49ee-bfa3-513887856a0b","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import the required packages \nimport os\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\nfrom langchain_community.document_loaders import UnstructuredHTMLLoader \nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nimport openai\nfrom langchain_community.document_loaders import PyPDFLoader\nimport pathlib\nfrom langchain.vectorstores import Chroma"},"cell_type":"code","id":"aa95c859-d935-4ef3-9606-d3b2f62c8234","outputs":[],"execution_count":1},{"source":"# Open AI Key \nopenai_api_key = os.environ[\"OPENAI_API_KEY\"]","metadata":{"executionCancelledAt":null,"executionTime":8,"lastExecutedAt":1750442147008,"lastExecutedByKernel":"3ba2e33b-5d82-49ee-bfa3-513887856a0b","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Open AI Key \nopenai_api_key = os.environ[\"OPENAI_API_KEY\"]"},"cell_type":"code","id":"e15ae1a5-b9e6-479a-9363-dec71990df35","outputs":[],"execution_count":2},{"source":"import pathlib\nimport openai\n\n# Open the audio file for processing \naudio_file_path = pathlib.Path(\"user_input_audio.mp3\")\n\nwith audio_file_path.open(\"rb\") as audio_file:\n    user_transcript = openai.audio.transcriptions.create(\n        model=\"whisper-1\",\n        file=audio_file\n    )\n\nuser_transcript_response = user_transcript.text\n\nprint(user_transcript_response)","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"af543701-df99-4384-8466-51f3b47f213f","outputs":[{"output_type":"stream","name":"stdout","text":"The procedure EPB system fault warning has appeared. What does this mean and what should I do about it?\n"}],"execution_count":17},{"source":"### Building the RAG","metadata":{},"cell_type":"markdown","id":"481f6fc8-f559-4aa6-abd0-1af5bc3516b0"},{"source":"# Load document \nloader = PyPDFLoader(file_path=\"car_manual.pdf\")\ncar_docs = loader.load() ","metadata":{"executionCancelledAt":null,"executionTime":298,"lastExecutedAt":1750442347035,"lastExecutedByKernel":"3ba2e33b-5d82-49ee-bfa3-513887856a0b","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load document \nloader = PyPDFLoader(file_path=\"car_manual.pdf\")\ncar_docs = loader.load() "},"cell_type":"code","id":"2b233a7a-3843-40b3-b4ed-93858bd61511","outputs":[],"execution_count":6},{"source":"# Define Splitter \nrc_splitter = RecursiveCharacterTextSplitter(\n    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"], \n    chunk_size=1000,\n    chunk_overlap=200\n) \n\ndocs = rc_splitter.split_documents(car_docs)","metadata":{"executionCancelledAt":null,"executionTime":13,"lastExecutedAt":1750442349715,"lastExecutedByKernel":"3ba2e33b-5d82-49ee-bfa3-513887856a0b","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define Splitter \nrc_splitter = RecursiveCharacterTextSplitter(\n    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"], \n    chunk_size=1000,\n    chunk_overlap=200\n) \n\ndocs = rc_splitter.split_documents(car_docs)"},"cell_type":"code","id":"3ce3adb6-13d5-4dd9-8282-f9543816a00d","outputs":[],"execution_count":7},{"source":"# Define embedding function \nembedding_function = OpenAIEmbeddings(api_key=openai_api_key, model='text-embedding-3-small') \n\n# Store the embeddings in Chroma vector database\nvectorstore = Chroma.from_documents(\n    documents=docs, \n    embedding=embedding_function, \n)\n\n# Create Chroma retriever\nretriever = vectorstore.as_retriever()","metadata":{"executionCancelledAt":null,"executionTime":3160,"lastExecutedAt":1750442414845,"lastExecutedByKernel":"3ba2e33b-5d82-49ee-bfa3-513887856a0b","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define embedding function \nembedding_function = OpenAIEmbeddings(api_key=openai_api_key, model='text-embedding-3-small') \n\n# Store the embeddings in Chroma vector database\nvectorstore = Chroma.from_documents(\n    documents=docs, \n    embedding=embedding_function, \n)\n\n# Create Chroma retriever\nretriever = vectorstore.as_retriever()"},"cell_type":"code","id":"726822ad-0f37-44dc-b8ba-d26e53a0e5e9","outputs":[],"execution_count":8},{"source":"# Initialize LLM\nllm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=openai_api_key, temperature=0)","metadata":{"executionCancelledAt":null,"executionTime":302,"lastExecutedAt":1750442434493,"lastExecutedByKernel":"3ba2e33b-5d82-49ee-bfa3-513887856a0b","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialize LLM\nllm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=openai_api_key, temperature=0)"},"cell_type":"code","id":"e03563f2-7305-44be-93a1-62a9c39a51b7","outputs":[],"execution_count":9},{"source":"# Define Prompt Template\nprompt = ChatPromptTemplate.from_template(\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\")","metadata":{"executionCancelledAt":null,"executionTime":8,"lastExecutedAt":1750442470136,"lastExecutedByKernel":"3ba2e33b-5d82-49ee-bfa3-513887856a0b","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define Prompt Template\nprompt = ChatPromptTemplate.from_template(\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\")"},"cell_type":"code","id":"2a89963f-86f4-47b7-ba7b-aaf5694ea9d5","outputs":[],"execution_count":10},{"source":"# Define RAG chain\nrag_chain = (\n    {\"context\": retriever, \"question\": RunnablePassthrough()} \n    | prompt \n    | llm \n)","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1750442494090,"lastExecutedByKernel":"3ba2e33b-5d82-49ee-bfa3-513887856a0b","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define RAG chain\nrag_chain = (\n    {\"context\": retriever, \"question\": RunnablePassthrough()} \n    | prompt \n    | llm \n)"},"cell_type":"code","id":"a5fd04e7-f092-4800-a5a7-0a7af8270f1c","outputs":[],"execution_count":11},{"source":"# Invoke RAG chain with a specific query\nquery = \"The Gasoline Particular Filter Full warning has appeared. What does this mean and what should I do about it?\"\n\nllm_response = rag_chain.invoke(query).content\n\nprint(llm_response)","metadata":{"executionCancelledAt":null,"executionTime":1519,"lastExecutedAt":1750443130233,"lastExecutedByKernel":"3ba2e33b-5d82-49ee-bfa3-513887856a0b","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Invoke RAG chain with a specific query\nquery = \"The Gasoline Particular Filter Full warning has appeared. What does this mean and what should I do about it?\"\n\nllm_response = rag_chain.invoke(query).content\n\nprint(llm_response)","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"cell_type":"code","id":"939bde5c-e40c-413b-870e-c2878f322094","outputs":[{"output_type":"stream","name":"stdout","text":"The Gasoline Particular Filter Full warning indicates that the gasoline particulate filter is full. You should consult an MG Authorised Repairer as soon as possible to address this issue.\n"}],"execution_count":23},{"source":"# Text to speech \nchatbot_audio = openai.audio.speech.create(\n    model=\"gpt-4o-mini-tts\", \n    voice=\"onyx\", \n    input=llm_response\n    )\n\naudio_file = chatbot_audio.stream_to_file(\"user_output_1.mp3\")","metadata":{"executionCancelledAt":null,"executionTime":2554,"lastExecutedAt":1750443183438,"lastExecutedByKernel":"3ba2e33b-5d82-49ee-bfa3-513887856a0b","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Text to speech \nchatbot_audio = openai.audio.speech.create(\n    model=\"gpt-4o-mini-tts\", \n    voice=\"onyx\", \n    input=llm_response\n    )\n\naudio_file = chatbot_audio.stream_to_file(\"user_output_1.mp3\")"},"cell_type":"code","id":"b0a5f094-996d-4948-960e-dee183e3d0e3","outputs":[],"execution_count":25}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}